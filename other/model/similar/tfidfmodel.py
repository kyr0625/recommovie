# -*- coding: utf-8 -*-
"""tfidfmodel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1akO7OR4E9MwaiD8M0TQOPee0YoPZCqLo
"""

# train_tfidf 해서 pkl -> 이 pkl 전체 영화해서 전체 pkl

!pip install konlpy

!pip install pymysql

# https://blog.naver.com/jjs1608/222879115999 참고, 책(파이썬 머신러닝 완벽 가이드)
import pandas as pd
import re
import joblib
import os
from konlpy.tag import Okt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


import pymysql

_database = {'host': 'asiente-db.czm25bubs03r.ap-northeast-2.rds.amazonaws.com',
            'port' : 3306,
            'user' : 'minji',
            'passwd' : '1234',
            'db' : 'movie',
            'charset' : 'utf8'}

conn = pymysql.connect(host=_database['host'],
                       port=_database['port'],
                       user=_database['user'],
                       passwd=_database['passwd'],
                       db=_database['db'],
                       charset=_database['charset'])

cur = conn.cursor()

query = "SELECT movieTitle, movieStory FROM movies"
cur.execute(query)

data = cur.fetchall()
data_df = pd.DataFrame(data)
conn.commit()
cur.close()
conn.close()
data_df.columns = ["title", "story"]



data_df = data_df.fillna(' ')

# 숫자제거
data_df['story'] = data_df['story'].apply(lambda x: re.sub(r"\d+", " ", x))

# 중복되는 특수문자
data_df['story'] = data_df['story'].apply(lambda x:re.sub(r"[\/?.,;~!^]{2,}", "", x))

# 형태소 단어 토큰화
okt = Okt()
def okt_tokenizer(text):
    tokens_ko = okt.morphs(text)  #형태소 반환
    return tokens_ko


tfidf_vect = TfidfVectorizer(tokenizer=okt_tokenizer, ngram_range=(1, 2), min_df=3, max_df=0.9)
tfidf_vect.fit(data_df['story'])
joblib.dump(tfidf_vect, 'similar_tfidf_vect.pkl')


tfidf_matrix_train = tfidf_vect.transform(data_df['story'])
joblib.dump(tfidf_matrix_train,'similar_tfidf_matrix_train.pkl')
# #print(tfidf_matrix_train.shape) # 몇개 문장에서 몇개 단어인지

# cosine_sim = cosine_similarity(tfidf_matrix_train, tfidf_matrix_train)
# # print(cosine_sim.shape) # 모든 문장 유사도 연산 결과 (자기 자신 포함)

# title_to_index = dict(zip(train_df['title'], train_df.index))

title_to_index = dict(zip(data_df['title'], data_df.index))

joblib.dump(title_to_index,'similar_title_to_index.pkl')

index_to_title = dict(zip(data_df.index, data_df['title']))

joblib.dump(index_to_title,'similar_index_to_title.pkl')